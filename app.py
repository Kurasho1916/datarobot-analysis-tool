import streamlit as st
import os
import requests
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import gaussian_kde

# =============================================================================
# ãƒ—ãƒ­ã‚­ã‚·ãƒ»è¨¼æ˜æ›¸è¨­å®š
# =============================================================================
CA = r"C:\Users\024044\OneDrive - æ ªå¼ä¼šç¤¾ï¼§ï¼³ãƒ¦ã‚¢ã‚µ\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\DXé“å ´\AIé“å ´\www.globalsign.crt"
os.environ["HTTP_PROXY"] = "http://172.17.20.158:3128"
os.environ["HTTPS_PROXY"] = "http://172.17.20.158:3128"
os.environ["REQUESTS_CA_BUNDLE"] = CA
os.environ["SSL_CERT_FILE"] = CA

# import datarobot as dr
# from datarobot.enums import INSIGHTS_SOURCES
# from datarobot import insights

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Meiryo']
plt.rcParams['axes.unicode_minus'] = False

# =============================================================================
# Streamlitè¨­å®š
# =============================================================================
st.set_page_config(page_title="DataRobotåˆ†æãƒ„ãƒ¼ãƒ«", layout="wide")

# =============================================================================
# Session StateåˆæœŸåŒ–
# =============================================================================
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'model' not in st.session_state:
    st.session_state.model = None
if 'feature_impact_df' not in st.session_state:
    st.session_state.feature_impact_df = pd.DataFrame()
if 'shap_impact_df' not in st.session_state:
    st.session_state.shap_impact_df = pd.DataFrame()
if 'shap_distributions_df' not in st.session_state:
    st.session_state.shap_distributions_df = pd.DataFrame()

# =============================================================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®šï¼ˆæœ€å°é™ï¼‰
# =============================================================================
st.sidebar.header("âš™ï¸ æ¥ç¶šè¨­å®š")

mode = st.sidebar.radio(
    "ãƒ¢ãƒ¼ãƒ‰é¸æŠ",
    ["ğŸ” æ¥ç¶šè¨ºæ–­", "ğŸ“Š åˆ†æå®Ÿè¡Œ"]
)

API_TOKEN = st.sidebar.text_input(
    "APIãƒˆãƒ¼ã‚¯ãƒ³", 
    value="Njk2ZGNlZTBkZWU3NzcxNzBhYjhkN2VhOk5yRFMyU3kwQzlmMlJMZ05pWWQ5am5sbzlyNVJMakZ2WEFsVU82ZjlBUG89",
    type="password",
    help="DataRobotã®Developer Tools â†’ APIã‚­ãƒ¼ã‹ã‚‰å–å¾—"
)

ENDPOINT = st.sidebar.text_input(
    "ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ",
    value="https://app.datarobot.com/api/v2",
    help="é€šå¸¸ã¯ https://app.datarobot.com/api/v2"
)

MODEL_ID = st.sidebar.text_input(
    "ãƒ¢ãƒ‡ãƒ«ID",
    value="695c981386dbc28805fcd879",
    help="DataRobotãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¢ãƒ‡ãƒ«IDã‚’å…¥åŠ›"
)

# =============================================================================
# ãƒ¢ãƒ¼ãƒ‰1: æ¥ç¶šè¨ºæ–­
# =============================================================================
if mode == "ğŸ” æ¥ç¶šè¨ºæ–­":
    st.title("ğŸ” DataRobot æ¥ç¶šè¨ºæ–­")
    st.info("DataRobotã¸ã®æ¥ç¶šçŠ¶æ…‹ã‚’è©³ã—ãè¨ºæ–­ã—ã¾ã™")
    
    if st.button("ğŸš€ è¨ºæ–­é–‹å§‹", type="primary"):
        
        # ========== 1. è¨¼æ˜æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª ==========
        st.header("1ï¸âƒ£ è¨¼æ˜æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª")
        if os.path.exists(CA):
            st.success(f"âœ“ è¨¼æ˜æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã™")
            st.code(CA)
        else:
            st.error(f"âŒ è¨¼æ˜æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.code(CA)
            st.stop()
        
        # ========== 2. ãƒ—ãƒ­ã‚­ã‚·æ¥ç¶šãƒ†ã‚¹ãƒˆ ==========
        st.header("2ï¸âƒ£ ãƒ—ãƒ­ã‚­ã‚·æ¥ç¶šãƒ†ã‚¹ãƒˆ")
        try:
            response = requests.get(
                "https://www.google.com",
                proxies={
                    "http": "http://172.17.20.158:3128",
                    "https": "http://172.17.20.158:3128"
                },
                verify=CA,
                timeout=10
            )
            st.success(f"âœ“ ãƒ—ãƒ­ã‚­ã‚·æ¥ç¶šæˆåŠŸï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}ï¼‰")
        except Exception as e:
            st.error(f"âŒ ãƒ—ãƒ­ã‚­ã‚·æ¥ç¶šã‚¨ãƒ©ãƒ¼")
            st.exception(e)
            st.warning("ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        # ========== 3. DataRobot SDKèªè¨¼ãƒ†ã‚¹ãƒˆ ==========
        st.header("3ï¸âƒ£ DataRobot SDKèªè¨¼ãƒ†ã‚¹ãƒˆ")
        
        auth_success = False
        
        try:
            # DataRobot SDKæ¥ç¶š
            dr.Client(endpoint=ENDPOINT, token=API_TOKEN)
            st.success("âœ“ DataRobot SDKæ¥ç¶šæˆåŠŸ")
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå–å¾—ã§èªè¨¼ç¢ºèª
            try:
                projects = dr.Project.list()
                st.success(f"âœ“ èªè¨¼æˆåŠŸï¼ˆã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {len(projects)}ä»¶ï¼‰")
                auth_success = True
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±è¡¨ç¤º
                st.info("ğŸ“Œ èªè¨¼æƒ…å ±ãŒæ­£å¸¸ã«æ©Ÿèƒ½ã—ã¦ã„ã¾ã™")
                
            except Exception as e:
                st.error(f"âŒ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå–å¾—å¤±æ•—: {e}")
                st.stop()
        
        except Exception as e:
            st.error(f"âŒ SDKæ¥ç¶šã‚¨ãƒ©ãƒ¼")
            st.exception(e)
            
            st.warning("### ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°")
            st.write("1. **APIãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç¢ºèª**")
            st.write("   - DataRobot â†’ Developer Tools â†’ APIã‚­ãƒ¼")
            st.write("   - ã€Œdx_pythonã€ã‚­ãƒ¼ãŒã€Œã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã€ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèª")
            st.write("")
            st.write("2. **ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèª**")
            st.code("https://app.datarobot.com/api/v2")
            st.write("")
            st.write("3. **ãƒ—ãƒ­ã‚­ã‚·ãƒ»è¨¼æ˜æ›¸è¨­å®šã‚’ç¢ºèª**")
            st.code(f"è¨¼æ˜æ›¸: {CA}")
            st.code("ãƒ—ãƒ­ã‚­ã‚·: http://172.17.20.158:3128")
            
            st.stop()
        
        if not auth_success:
            st.error("âŒ èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
            st.stop()
        
        # ========== 4. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§å–å¾— ==========
        st.header("4ï¸âƒ£ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§")
        
        if len(projects) > 0:
            st.success(f"âœ“ {len(projects)}ä»¶ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½")
            
            project_list = []
            for proj in projects[:10]:
                project_list.append({
                    'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå': proj.project_name,
                    'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID': proj.id,
                    'ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ': proj.target,
                    'ä½œæˆæ—¥': str(proj.created)[:10]
                })
            
            st.dataframe(pd.DataFrame(project_list), use_container_width=True)
        else:
            st.warning("ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
            st.stop()
        
        # ========== 5. ãƒ¢ãƒ‡ãƒ«å–å¾—ãƒ†ã‚¹ãƒˆ ==========
        st.header("5ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—")
        
        try:
            all_models = []
            
            with st.spinner(f"ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—ä¸­... (å¯¾è±¡: {len(projects[:5])}ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ)"):
                for proj in projects[:5]:
                    try:
                        models = proj.get_models()
                        
                        for model in models[:10]:
                            all_models.append({
                                'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå': proj.project_name,
                                'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID': proj.id,
                                'ãƒ¢ãƒ‡ãƒ«ID': model.id,
                                'ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—': model.model_type,
                                'ã‚µãƒ³ãƒ—ãƒ«%': model.sample_pct,
                                'ãƒ¡ãƒˆãƒªãƒƒã‚¯': getattr(model, 'metrics', {}).get(proj.metric, 'N/A') if hasattr(model, 'metrics') else 'N/A'
                            })
                    except Exception as e:
                        st.warning(f"âš  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ '{proj.project_name}' ã®ãƒ¢ãƒ‡ãƒ«å–å¾—å¤±æ•—")
                        continue
            
            if len(all_models) > 0:
                st.success(f"âœ“ {len(all_models)}ä»¶ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç™ºè¦‹")
                
                models_df = pd.DataFrame(all_models)
                
                # æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                search_model_id = st.text_input("ğŸ” ãƒ¢ãƒ‡ãƒ«IDã§æ¤œç´¢", value=MODEL_ID)
                
                if search_model_id:
                    filtered = models_df[models_df['ãƒ¢ãƒ‡ãƒ«ID'].str.contains(search_model_id, case=False)]
                    
                    if len(filtered) > 0:
                        st.success(f"âœ… ãƒ¢ãƒ‡ãƒ«ID '{search_model_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼")
                        st.dataframe(filtered, use_container_width=True)
                        
                        st.info("ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ŒğŸ“Š åˆ†æå®Ÿè¡Œã€ãƒ¢ãƒ¼ãƒ‰ã§ä½¿ç”¨ã§ãã¾ã™")
                    else:
                        st.warning(f"âš  ãƒ¢ãƒ‡ãƒ«ID '{search_model_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        st.write("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§:")
                        st.dataframe(models_df, use_container_width=True)
                else:
                    st.dataframe(models_df, use_container_width=True)
                
                # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                csv = models_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (CSV)",
                    data=csv,
                    file_name="datarobot_models.csv",
                    mime="text/csv"
                )
            else:
                st.warning("ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        except Exception as e:
            st.error("âŒ ãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼")
            st.exception(e)
        
        st.success("ğŸ‰ è¨ºæ–­å®Œäº†")

# =============================================================================
# ãƒ¢ãƒ¼ãƒ‰2: åˆ†æå®Ÿè¡Œ
# =============================================================================
elif mode == "ğŸ“Š åˆ†æå®Ÿè¡Œ":
    st.title("ğŸ“Š DataRobotåˆ†æãƒ„ãƒ¼ãƒ«")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³
    if st.button("ğŸš€ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿", type="primary"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ========== ã‚¹ãƒ†ãƒƒãƒ—1: æ¥ç¶š (20%) ==========
        status_text.info("â³ DataRobotã«æ¥ç¶šä¸­...")
        progress_bar.progress(20)
        
        try:
            dr.Client(endpoint=ENDPOINT, token=API_TOKEN)
            status_text.success("âœ“ æ¥ç¶šæˆåŠŸ")
        except Exception as e:
            st.error(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            st.warning("ã€ŒğŸ” æ¥ç¶šè¨ºæ–­ã€ãƒ¢ãƒ¼ãƒ‰ã§è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            st.stop()
        
        # ========== ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ¢ãƒ‡ãƒ«å–å¾— (40%) ==========
        status_text.info(f"â³ ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ä¸­... (ID: {MODEL_ID})")
        progress_bar.progress(40)
        
        try:
            # å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢
            projects = dr.Project.list()
            
            model = None
            project_id = None
            
            for proj in projects:
                try:
                    models = proj.get_models()
                    for m in models:
                        if m.id == MODEL_ID:
                            model = m
                            project_id = proj.id
                            break
                    if model:
                        break
                except:
                    continue
            
            if not model:
                st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ID '{MODEL_ID}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                st.warning("ã€ŒğŸ” æ¥ç¶šè¨ºæ–­ã€ãƒ¢ãƒ¼ãƒ‰ã§åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«IDã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                st.stop()
            
            st.session_state.model = model
            st.sidebar.success(f"âœ“ ãƒ¢ãƒ‡ãƒ«: {model.model_type}")
            st.sidebar.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID: {project_id}")
            status_text.success("âœ“ ãƒ¢ãƒ‡ãƒ«å–å¾—æˆåŠŸ")
            
        except Exception as e:
            st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            st.exception(e)
            st.stop()
        
        # ========== ã‚¹ãƒ†ãƒƒãƒ—3: Feature Impact (60%) ==========
        status_text.info("â³ Feature Impactå–å¾—ä¸­...")
        progress_bar.progress(60)
        
        try:
            impacts = model.get_or_request_feature_impact()
            st.session_state.feature_impact_df = pd.DataFrame(impacts).sort_values(by="impactNormalized", ascending=False)
            st.success(f"âœ“ Feature Impactå–å¾—å®Œäº† ({len(st.session_state.feature_impact_df)}ä»¶)")
        except Exception as e:
            st.warning(f"âš  Feature Impactå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            st.session_state.feature_impact_df = pd.DataFrame()
        
        # ========== ã‚¹ãƒ†ãƒƒãƒ—4: SHAP ãƒ‡ãƒ¼ã‚¿ (80%) ==========
        status_text.info("â³ SHAPãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        progress_bar.progress(80)
        
        # SHAP Impact
        try:
            shap_impacts_list = insights.ShapImpact.list(MODEL_ID)

            if not shap_impacts_list:
                st.info("SHAP Impactã‚’è¨ˆç®—ä¸­...ï¼ˆæœ€å¤§3åˆ†ï¼‰")
                job = insights.ShapImpact.compute(MODEL_ID, source=INSIGHTS_SOURCES.VALIDATION, quick_compute=True)
                job.wait_for_completion(max_wait=180)
                shap_impacts_list = insights.ShapImpact.list(MODEL_ID)

            if shap_impacts_list:
                shap_impact = shap_impacts_list[0]
                shap_impact.sort('-impact_normalized')
                st.session_state.shap_impact_df = pd.DataFrame(shap_impact.shap_impacts)
                st.success(f"âœ“ SHAP Impactå–å¾—å®Œäº† ({len(st.session_state.shap_impact_df)}ä»¶)")
            else:
                st.session_state.shap_impact_df = pd.DataFrame()
                st.warning("âš  SHAP Impactãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        except Exception as e:
            st.warning(f"âš  SHAP Impactå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            st.session_state.shap_impact_df = pd.DataFrame()
        
        # SHAP Distributions
        try:
            shap_dist_list = insights.ShapDistributions.list(MODEL_ID)

            if not shap_dist_list:
                st.info("SHAP Distributionsã‚’è¨ˆç®—ä¸­...ï¼ˆæœ€å¤§3åˆ†ï¼‰")
                job = insights.ShapDistributions.compute(MODEL_ID, source=INSIGHTS_SOURCES.VALIDATION, quick_compute=True)
                job.wait_for_completion(max_wait=180)
                shap_dist_list = insights.ShapDistributions.list(MODEL_ID)

            if shap_dist_list:
                shap_dist = shap_dist_list[0]
                dist_rows = []
                for feature in shap_dist.features:
                    feature_name = feature.get('feature')
                    feature_type = feature.get('feature_type')
                    for sv in feature.get('shap_values', []):
                        dist_rows.append({
                            'feature': feature_name,
                            'feature_type': feature_type,
                            'row_index': sv.get('row_index'),
                            'prediction_value': sv.get('prediction_value'),
                            'feature_rank': sv.get('feature_rank'),
                            'feature_value': sv.get('feature_value'),
                            'shap_value': sv.get('shap_value')
                        })
                
                st.session_state.shap_distributions_df = pd.DataFrame(dist_rows)
                st.success(f"âœ“ SHAP Distributionså–å¾—å®Œäº† ({len(st.session_state.shap_distributions_df)}ä»¶)")
            else:
                st.session_state.shap_distributions_df = pd.DataFrame()
                st.warning("âš  SHAP Distributionsãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        except Exception as e:
            st.warning(f"âš  SHAP Distributionså–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            st.session_state.shap_distributions_df = pd.DataFrame()
        
        # ========== å®Œäº† (100%) ==========
        progress_bar.progress(100)
        status_text.success("âœ“ ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†")
        st.session_state.data_loaded = True
        st.rerun()
    
    # ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚°ãƒ©ãƒ•è¡¨ç¤º
    if st.session_state.data_loaded:
        model = st.session_state.model
        feature_impact_df = st.session_state.feature_impact_df
        shap_impact_df = st.session_state.shap_impact_df
        shap_distributions_df = st.session_state.shap_distributions_df
        
        st.divider()
        
        # =============================================================================
        # â‘  ç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆï¼ˆä¸Šä½Nä»¶ï¼‰
        # =============================================================================
        st.header("â‘  ç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ (Permutation)")
        
        if len(feature_impact_df) > 0:
            # æœ€å¤§å€¤ã‚’å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿æ•°ã«åˆ¶é™
            max_available = len(feature_impact_df)
            
            # ãƒ—ãƒ­ãƒƒãƒˆè¨­å®šï¼ˆã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ï¼‰
            col1, col2 = st.columns([3, 1])
            with col1:
                num_features_impact = st.slider(
                    "è¡¨ç¤ºã™ã‚‹ç‰¹å¾´é‡ã®æ•°",
                    min_value=1,
                    max_value=max_available,
                    value=min(10, max_available),
                    key="impact_slider",
                    help="ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®ã‚°ãƒ©ãƒ•ã«è¡¨ç¤ºã™ã‚‹ç‰¹å¾´é‡ã®æ•°"
                )
            
            top_n_impact = feature_impact_df.nlargest(num_features_impact, 'impactNormalized').sort_values('impactNormalized')

            fig1, ax1 = plt.subplots(figsize=(10, max(6, num_features_impact * 0.4)))
            bars = ax1.barh(top_n_impact['featureName'], top_n_impact['impactNormalized'], 
                            color='steelblue', edgecolor='navy', linewidth=1.2)

            colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(bars)))
            for bar, color in zip(bars, colors):
                bar.set_color(color)

            ax1.set_xlabel('Normalized Impact', fontsize=12, fontweight='bold')
            ax1.set_xlim(0, 1)
            ax1.set_title(f'Top {num_features_impact} Feature Impact (Permutation)\nModel: {model.model_type}', 
                          fontsize=14, fontweight='bold', pad=20)
            ax1.grid(axis='x', alpha=0.3, linestyle='--')
            ax1.set_facecolor('#F8F9FA')
            fig1.tight_layout()
            
            st.pyplot(fig1)
            
            with st.expander("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º"):
                st.dataframe(
                    top_n_impact[['featureName', 'impactNormalized', 'impactUnnormalized']],
                    use_container_width=True
                )
                
                # CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                csv_impact = top_n_impact.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    "ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_impact,
                    file_name=f"feature_impact_top{num_features_impact}.csv",
                    mime="text/csv"
                )
        else:
            st.warning("âš  Feature Impactãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        
        st.divider()
        
        # =============================================================================
        # â‘¡ ç‰¹å¾´é‡ã®ä½œç”¨ï¼ˆSHAP Impactç›¸é–¢ãƒ—ãƒ­ãƒƒãƒˆï¼‰
        # =============================================================================
        st.header("â‘¡ ç‰¹å¾´é‡ã®ä½œç”¨ (SHAP Analysis)")
        
        # ãƒ—ãƒ­ãƒƒãƒˆè¡¨ç¤ºè¨­å®š
        show_shap_correlation = st.checkbox(
            "SHAPç›¸é–¢ãƒ—ãƒ­ãƒƒãƒˆã‚’è¡¨ç¤º",
            value=True,
            key="show_shap_corr"
        )
        
        if len(shap_impact_df) > 0 and len(shap_distributions_df) > 0 and show_shap_correlation:
            
            # é‡è¦åº¦é †ã«ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            all_shap_features = shap_impact_df.sort_values('impact_normalized', ascending=False)['feature_name'].tolist()
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Top 10
            default_features = all_shap_features[:min(10, len(all_shap_features))]
            
            # ç‰¹å¾´é‡é¸æŠï¼ˆã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ï¼‰
            col1, col2 = st.columns([4, 1])
            with col1:
                selected_features = st.multiselect(
                    "ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ç‰¹å¾´é‡ã‚’é¸æŠï¼ˆé‡è¦åº¦é †ï¼‰:",
                    options=all_shap_features,
                    default=default_features,
                    help="æœ€å¤§20å€‹ã¾ã§é¸æŠå¯èƒ½ã§ã™",
                    key="shap_features_select"
                )
            with col2:
                show_equation = st.checkbox(
                    "å›å¸°å¼ã‚’è¡¨ç¤º",
                    value=True,
                    key="show_eq"
                )
            
            if len(selected_features) == 0:
                st.warning("âš  å°‘ãªãã¨ã‚‚1ã¤ã®ç‰¹å¾´é‡ã‚’é¸æŠã—ã¦ãã ã•ã„")
            elif len(selected_features) > 20:
                st.error("âŒé¸æŠã§ãã‚‹ç‰¹å¾´é‡ã¯æœ€å¤§20å€‹ã¾ã§ã§ã™")
            else:
                # ã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’å‹•çš„ã«èª¿æ•´
                num_selected = len(selected_features)
                
                if num_selected <= 5:
                    n_cols = num_selected
                    n_rows = 1
                elif num_selected <= 10:
                    n_cols = 5
                    n_rows = 2
                elif num_selected <= 15:
                    n_cols = 5
                    n_rows = 3
                else:
                    n_cols = 5
                    n_rows = 4

                fig2, axes2 = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3.5))
                
                # axesã‚’1æ¬¡å…ƒé…åˆ—ã«å¤‰æ›
                if n_rows == 1 and n_cols == 1:
                    axes2 = [axes2]
                elif n_rows == 1 or n_cols == 1:
                    axes2 = axes2.flatten()
                else:
                    axes2 = axes2.flatten()

                for idx, feature_name in enumerate(selected_features):
                    ax = axes2[idx]
                    
                    feature_data = shap_distributions_df[shap_distributions_df['feature'] == feature_name].copy()
                    
                    if len(feature_data) > 0:
                        feature_data['feature_value_num'] = pd.to_numeric(feature_data['feature_value'], errors='coerce')
                        feature_data = feature_data.dropna(subset=['feature_value_num', 'shap_value'])
                        
                        if len(feature_data) > 10:
                            q1 = feature_data['feature_value_num'].quantile(0.05)
                            q3 = feature_data['feature_value_num'].quantile(0.95)
                            feature_data = feature_data[
                                (feature_data['feature_value_num'] >= q1) & 
                                (feature_data['feature_value_num'] <= q3)
                            ]
                            
                            # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å‰Šé™¤ â†’ å˜è‰²ã«å¤‰æ›´
                            scatter = ax.scatter(
                                feature_data['feature_value_num'], 
                                feature_data['shap_value'],
                                color='steelblue',
                                alpha=0.6,
                                s=30,
                                edgecolors='black',
                                linewidth=0.5
                            )
                            
                            corr = feature_data['feature_value_num'].corr(feature_data['shap_value'])
                            
                            z = np.polyfit(feature_data['feature_value_num'], feature_data['shap_value'], 1)
                            p = np.poly1d(z)
                            x_line = feature_data['feature_value_num'].sort_values()
                            
                            if show_equation:
                                label_text = f'y = {z[0]:.3f}x + {z[1]:.3f}\nCorr: {corr:.3f}'
                            else:
                                label_text = f'Corr: {corr:.3f}'
                            
                            ax.plot(x_line, p(x_line), "r--", alpha=0.8, linewidth=2, label=label_text)
                            
                            ax.set_title(f'{feature_name}', fontsize=10, fontweight='bold')
                            ax.set_xlabel('Feature Value', fontsize=9)
                            ax.set_ylabel('SHAP Value', fontsize=9)
                            ax.legend(loc='best', fontsize=8)
                            ax.grid(True, alpha=0.3)
                        else:
                            ax.text(0.5, 0.5, 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³', ha='center', va='center', fontsize=12)
                            ax.set_title(f'{feature_name}', fontsize=10)
                    else:
                        ax.text(0.5, 0.5, 'ãƒ‡ãƒ¼ã‚¿ãªã—', ha='center', va='center', fontsize=12)
                        ax.set_title(f'{feature_name}', fontsize=10)
                
                # ä½™åˆ†ãªè»¸ã‚’éè¡¨ç¤º
                for idx in range(num_selected, len(axes2)):
                    axes2[idx].axis('off')

                fig2.suptitle(f'Feature Impact on Prediction (SHAP Analysis)\nModel: {model.model_type}', 
                              fontsize=16, fontweight='bold', y=0.995)
                fig2.tight_layout()
                
                st.pyplot(fig2)
        
        elif not show_shap_correlation:
            st.info("â„¹ï¸ SHAPç›¸é–¢ãƒ—ãƒ­ãƒƒãƒˆã¯éè¡¨ç¤ºã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™")
        else:
            st.warning("âš  SHAPãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        
        st.divider()
        
        # =============================================================================
        # â‘¢ SHAPåˆ†å¸ƒï¼ˆæŒ‡æ¨™ä»˜ãï¼‰
        # =============================================================================
        st.header("â‘¢ SHAPå€¤ã®åˆ†å¸ƒ")
        
        if len(shap_distributions_df) > 0:
            feature_stats = []
            
            for feature_name in shap_distributions_df['feature'].unique():
                feature_data = shap_distributions_df[shap_distributions_df['feature'] == feature_name]
                shap_vals = feature_data['shap_value'].values
                
                stats = {
                    'feature': feature_name,
                    'mean_abs_shap': np.abs(shap_vals).mean(),
                    'std_shap': shap_vals.std(),
                    'positive_ratio': (shap_vals > 0).mean() * 100,
                    'shap_range': shap_vals.max() - shap_vals.min(),
                    'skewness': pd.Series(shap_vals).skew()
                }
                feature_stats.append(stats)
            
            stats_df = pd.DataFrame(feature_stats).sort_values('mean_abs_shap', ascending=False)
            
            # æœ€å¤§å€¤ã‚’å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿æ•°ã«åˆ¶é™
            max_available_shap = len(stats_df)
            
            # ãƒ—ãƒ­ãƒƒãƒˆè¨­å®šï¼ˆã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ï¼‰
            num_features_shap_dist = st.slider(
                "è¡¨ç¤ºã™ã‚‹ç‰¹å¾´é‡ã®æ•°",
                min_value=1,
                max_value=max_available_shap,
                value=min(10, max_available_shap),
                key="shap_dist_slider",
                help="SHAPå€¤åˆ†å¸ƒã‚°ãƒ©ãƒ•ã«è¡¨ç¤ºã™ã‚‹ç‰¹å¾´é‡ã®æ•°"
            )
            
            top_n_features = stats_df.head(num_features_shap_dist)['feature'].tolist()
            top_n_data = shap_distributions_df[shap_distributions_df['feature'].isin(top_n_features)].copy()

            fig3, ax3 = plt.subplots(figsize=(14, max(10, num_features_shap_dist * 0.8)))

            for idx, feature_name in enumerate(top_n_features):
                feature_data = top_n_data[top_n_data['feature'] == feature_name]
                
                shap_values = feature_data['shap_value'].values
                feature_type = feature_data['feature_type'].iloc[0]
                
                if feature_type == 'C':
                    colors = np.array(['#AAAAAA'] * len(shap_values))
                    shap_values_to_plot = shap_values
                else:
                    try:
                        feature_values_numeric = pd.to_numeric(feature_data['feature_value'], errors='coerce')
                        valid_mask = ~feature_values_numeric.isna()
                        feature_values_numeric = feature_values_numeric[valid_mask]
                        shap_values_filtered = shap_values[valid_mask]
                        
                        if len(feature_values_numeric) > 0:
                            q1 = feature_values_numeric.quantile(0.05)
                            q3 = feature_values_numeric.quantile(0.95)
                            feature_values_clipped = feature_values_numeric.clip(q1, q3)
                            
                            if feature_values_clipped.max() != feature_values_clipped.min():
                                normalized_values = (feature_values_clipped - feature_values_clipped.min()) / \
                                                  (feature_values_clipped.max() - feature_values_clipped.min())
                            else:
                                normalized_values = np.ones(len(feature_values_clipped)) * 0.5
                            
                            cmap = plt.cm.coolwarm
                            colors = cmap(normalized_values)
                            shap_values_to_plot = shap_values_filtered
                        else:
                            colors = np.array(['#AAAAAA'] * len(shap_values))
                            shap_values_to_plot = shap_values
                    except:
                        colors = np.array(['#AAAAAA'] * len(shap_values))
                        shap_values_to_plot = shap_values
                
                if len(shap_values_to_plot) > 10:
                    try:
                        kde = gaussian_kde(shap_values_to_plot)
                        density = kde(shap_values_to_plot)
                        jitter_scale = 0.15 / (density.max() / density)
                        jitter_scale = np.clip(jitter_scale, 0.05, 0.25)
                        y_jitter = np.random.normal(0, 1, len(shap_values_to_plot)) * jitter_scale
                    except:
                        y_jitter = np.random.normal(0, 0.1, len(shap_values_to_plot))
                else:
                    y_jitter = np.random.normal(0, 0.1, len(shap_values_to_plot))
                
                y_positions = np.ones(len(shap_values_to_plot)) * idx + y_jitter
                
                ax3.scatter(
                    shap_values_to_plot,
                    y_positions,
                    c=colors,
                    alpha=0.6,
                    s=25,
                    edgecolors='none',
                    rasterized=True
                )

            ax3.axvline(x=0, color='#333333', linestyle='-', linewidth=1.5, alpha=0.7)

            y_labels = []
            for feature_name in top_n_features:
                stats = stats_df[stats_df['feature'] == feature_name].iloc[0]
                label = (f"{feature_name}\n"
                        f"Mean|SHAP|: {stats['mean_abs_shap']:.3f} "
                        f"Pos%: {stats['positive_ratio']:.1f}% "
                        f"Range: {stats['shap_range']:.3f}")
                y_labels.append(label)
            
            ax3.set_yticks(range(len(top_n_features)))
            ax3.set_yticklabels(y_labels, fontsize=9)
            ax3.set_ylim(-0.5, len(top_n_features) - 0.5)
            ax3.invert_yaxis()

            ax3.set_xlabel('SHAP value', fontsize=13, fontweight='bold')
            ax3.grid(True, alpha=0.2, axis='x', linestyle='--')
            ax3.set_facecolor('#FAFAFA')
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«å¤‰æ›´
            ax3.set_title(f'SHAPåˆ†å¸ƒ ({model.model_type})', 
                          fontsize=15, fontweight='bold', pad=20)

            sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=plt.Normalize(vmin=0, vmax=1))
            sm.set_array([])
            cbar = plt.colorbar(sm, ax=ax3, pad=0.02, aspect=30)
            cbar.set_label('Feature value', fontsize=11, fontweight='bold')
            cbar.set_ticks([0, 1])
            cbar.set_ticklabels(['Low', 'High'])

            fig3.tight_layout()
            st.pyplot(fig3)
            
            st.subheader(f"SHAPçµ±è¨ˆæŒ‡æ¨™ (Top {num_features_shap_dist})")
            st.dataframe(
                stats_df.head(num_features_shap_dist).style.format({
                    'mean_abs_shap': '{:.4f}',
                    'std_shap': '{:.4f}',
                    'positive_ratio': '{:.2f}%',
                    'shap_range': '{:.4f}',
                    'skewness': '{:.4f}'
                }),
                use_container_width=True
            )
            
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            csv_shap = stats_df.head(num_features_shap_dist).to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                "ğŸ“¥ SHAPçµ±è¨ˆã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_shap,
                file_name=f"shap_statistics_top{num_features_shap_dist}.csv",
                mime="text/csv"
            )
        else:
            st.warning("âš  SHAP Distributionsãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    else:
        st.info("ğŸ‘† ä¸Šã®ã€ŒğŸš€ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")

        st.info("ğŸ’¡ ãƒ¢ãƒ‡ãƒ«IDãŒæ­£ã—ã„ã‹ç¢ºèªã™ã‚‹ã«ã¯ã€ŒğŸ” æ¥ç¶šè¨ºæ–­ã€ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
